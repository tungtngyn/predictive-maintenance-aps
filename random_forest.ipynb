{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest\n",
    "This notebook fits a Random Forest model to the Scania Trucks Air Pressure System (APS) predictive maintenance dataset, obtained from [UCI's data repository](https://archive.ics.uci.edu/ml/datasets/APS+Failure+at+Scania+Trucks). \n",
    "\n",
    "In the Logistic Regression & Naive Bayes notebooks, grid searches were used for hyperparameter tuning. However, significantly more computational resources are required to fit a Random Forest model. Thus, this notebook will use Bayesian Optimization in lieu of grid search."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from hyperopt import fmin, tpe, hp\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.metrics import auc, roc_curve, precision_recall_curve, make_scorer, confusion_matrix\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.pipeline import Pipeline as imbPipeline\n",
    "\n",
    "sns.set()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.read_csv(r'./data/aps_failure_training_set_data_only.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_misclassification_cost(y, y_pred):\n",
    "    tn, fp, fn, tp = confusion_matrix(y, y_pred).ravel()\n",
    "    return 10*fp + 500*fn\n",
    "\n",
    "\n",
    "misclassification_cost = make_scorer(\n",
    "    calc_misclassification_cost,\n",
    "    greater_is_better=False,\n",
    "    needs_proba=False,\n",
    "    needs_threshold=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df --> X_train & y_train\n",
    "X_train = df_train.drop('class', axis=1)\n",
    "y_train = df_train['class']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "params_test = {\n",
    "    'n_estimators': 150,\n",
    "    'criterion': 'entropy',\n",
    "    'max_depth': None,\n",
    "    'min_samples_split': 2,\n",
    "    'min_samples_leaf': 6,\n",
    "    'max_features': 'sqrt',\n",
    "    'bootstrap': True,\n",
    "    'max_leaf_nodes': None,\n",
    "}\n",
    "\n",
    "clf = RandomForestClassifier(random_state=1, n_estimators=150, n_jobs=-1, **params_test)\n",
    "\n",
    "steps = [\n",
    "    ('impute', SimpleImputer(strategy='constant', fill_value=0)),\n",
    "    ('rf_clf', clf)\n",
    "]\n",
    "\n",
    "pipe = Pipeline(steps=steps)\n",
    "\n",
    "scores = cross_val_score(pipe, cv=3, X=X_train, y=y_train, scoring=misclassification_cost, n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "space = {\n",
    "    'fill_na': (hp.choice, (0, -1, -100, -10_000, -1_000_000, 'mean', 'most_frequent')),\n",
    "    'sampling': (hp.choice, (None, 'smote')),\n",
    "    'class_weight': (hp.choice, ('balanced', 'balanced_subsample')),\n",
    "    'criterion': (hp.choice, ('gini', 'entropy', 'log_loss')),\n",
    "    'max_depth': (hp.choice, (None, (hp.quniform, (2, 1000, 2)))),\n",
    "    'min_samples_split': (hp.qloguniform, (2, 10000, 2)),\n",
    "    'min_samples_leaf': (hp.qloguniform, (2, 10000, 2)),\n",
    "    'max_features': (hp.choice, ('sqrt', 'log2', None)), \n",
    "    'max_leaf_nodes': (hp.qloguniform, (2, 10000, 2))\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_results_file(cv_mean_cost, params):\n",
    "    with open(r'./logs/log_rf_bayes_opt.txt', mode='a') as f:\n",
    "        f.write('Cost = %i, Params = %s\\n' % (cv_mean_cost, params))\n",
    "    pass\n",
    "\n",
    "\n",
    "def objective(params):\n",
    "    print(params)\n",
    "    \n",
    "    # Initialize\n",
    "    params_rf = {\n",
    "        'class_weight': params['class_weight'],\n",
    "        'max_depth': None if params['max_depth'] == None else int(params['max_depth']),\n",
    "        'max_leaf_nodes': int(params['max_leaf_nodes'])\n",
    "    }\n",
    "    \n",
    "    print(params_rf)\n",
    "\n",
    "    steps = []\n",
    "\n",
    "    # Impute\n",
    "    if type(params['fill_na']) == int:\n",
    "        steps.append(('impute', SimpleImputer(strategy='constant', fill_value=params['fill_na'])))\n",
    "    else:\n",
    "        steps.append(('impute', SimpleImputer(strategy=params['fill_na'])))\n",
    "\n",
    "    # SMOTE\n",
    "    if params['sampling'] == 'smote':\n",
    "        steps.append(('smote', SMOTE(random_state=1)))\n",
    "        steps.append(('rf_clf', RandomForestClassifier(random_state=1, n_estimators=150, n_jobs=-1, **params_rf)))\n",
    "        pipe = imbPipeline(steps=steps)\n",
    "\n",
    "    else:\n",
    "        steps.append(('rf_clf', RandomForestClassifier(random_state=1, n_estimators=150, n_jobs=-1, **params_rf)))\n",
    "        pipe = Pipeline(steps=steps)\n",
    "\n",
    "    scores = cross_val_score(pipe, cv=5, X=X_train, y=y_train, scoring=misclassification_cost, n_jobs=-1)\n",
    "    cv_mean_cost = -scores.mean()\n",
    "\n",
    "    write_results_file(cv_mean_cost, params)\n",
    "\n",
    "    return cv_mean_cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'class_weight': 'balanced', 'fill_na': 'most_frequent', 'max_depth': 28.0, 'max_leaf_nodes': 34.066296707256896, 'sampling': None}\n",
      "{'class_weight': 'balanced', 'max_depth': 28, 'max_leaf_nodes': 34}\n",
      "{'class_weight': 'balanced', 'fill_na': 0, 'max_depth': 38.0, 'max_leaf_nodes': 1014.4419763257858, 'sampling': None}\n",
      "{'class_weight': 'balanced', 'max_depth': 38, 'max_leaf_nodes': 1014}\n",
      "{'class_weight': 'balanced_subsample', 'fill_na': 'most_frequent', 'max_depth': 44.0, 'max_leaf_nodes': 6417.028098616062, 'sampling': None}\n",
      "{'class_weight': 'balanced_subsample', 'max_depth': 44, 'max_leaf_nodes': 6417}\n",
      "{'class_weight': 'balanced_subsample', 'fill_na': 'mean', 'max_depth': 14.0, 'max_leaf_nodes': 3078.838118799532, 'sampling': 'smote'}\n",
      "{'class_weight': 'balanced_subsample', 'max_depth': 14, 'max_leaf_nodes': 3078}\n",
      "{'class_weight': 'balanced_subsample', 'fill_na': 0, 'max_depth': None, 'max_leaf_nodes': 407.5380221189031, 'sampling': 'smote'}\n",
      "{'class_weight': 'balanced_subsample', 'max_depth': None, 'max_leaf_nodes': 407}\n",
      "{'class_weight': 'balanced_subsample', 'fill_na': 0, 'max_depth': 2.0, 'max_leaf_nodes': 6910.846672927124, 'sampling': None}\n",
      "{'class_weight': 'balanced_subsample', 'max_depth': 2, 'max_leaf_nodes': 6910}\n",
      "{'class_weight': 'balanced_subsample', 'fill_na': 0, 'max_depth': 20.0, 'max_leaf_nodes': 75.56350722991468, 'sampling': 'smote'}\n",
      "{'class_weight': 'balanced_subsample', 'max_depth': 20, 'max_leaf_nodes': 75}\n",
      "{'class_weight': 'balanced_subsample', 'fill_na': 'mean', 'max_depth': None, 'max_leaf_nodes': 767.482989820026, 'sampling': None}\n",
      "{'class_weight': 'balanced_subsample', 'max_depth': None, 'max_leaf_nodes': 767}\n",
      "{'class_weight': 'balanced_subsample', 'fill_na': 'mean', 'max_depth': 24.0, 'max_leaf_nodes': 432.6196151842853, 'sampling': None}\n",
      "{'class_weight': 'balanced_subsample', 'max_depth': 24, 'max_leaf_nodes': 432}\n",
      "{'class_weight': 'balanced', 'fill_na': 'mean', 'max_depth': 36.0, 'max_leaf_nodes': 251.473162602303, 'sampling': 'smote'}\n",
      "{'class_weight': 'balanced', 'max_depth': 36, 'max_leaf_nodes': 251}\n",
      "100%|██████████| 10/10 [04:41<00:00, 28.11s/trial, best loss: 9374.0]\n"
     ]
    }
   ],
   "source": [
    "# Test run\n",
    "space = {\n",
    "    'fill_na': hp.choice('fill_na', [0, 'mean', 'most_frequent']),\n",
    "    'sampling': hp.choice('sampling', [None, 'smote']),\n",
    "    'class_weight': hp.choice('class_weight', ['balanced', 'balanced_subsample']),\n",
    "    'max_depth': hp.choice('max_depth', [None, hp.quniform('max_depth_int', 2, 50, 2)]),\n",
    "    'max_leaf_nodes': hp.loguniform('max_leaf_nodes', 0.1, 10)\n",
    "}\n",
    "\n",
    "best = fmin(fn=objective, space=space, max_evals=10, rstate=np.random.default_rng(1), algo=tpe.suggest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'class_weight': 1,\n",
       " 'fill_na': 0,\n",
       " 'max_depth': 1,\n",
       " 'max_depth_int': 20.0,\n",
       " 'max_leaf_nodes': 75.56350722991468,\n",
       " 'sampling': 1}"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.6 ('xgb')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "fb3f0c3a697a7256f3122816dd9f3ac634f951acfd855c57fce6592b991e3e66"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
